# -*- coding: utf-8 -*-
"""LSTM_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/034adarsh/Stock-Price-Prediction-Using-LSTM/blob/main/LSTM_model.ipynb

# Import all the required libraries

---
"""

import pandas as pd
import datetime as dt
from datetime import date
import matplotlib.pyplot as plt
import yfinance as yf
import numpy as np
import tensorflow as tf

"""# Define start day to fetch the dataset from the yahoo finance library

---


"""

START = "2015-01-01"
TODAY = date.today().strftime("%Y-%m-%d")

# Define a function to load the dataset

def load_data(ticker):
    data = yf.download(ticker, START, TODAY)
    data.reset_index(inplace=True)
    return data

data = load_data('AAPL')
df=data
df.head()

# Check if 'Date' column exists before dropping
if 'Date' in df.columns:
    df = df.drop(['Date'], axis=1)
df.head()

plt.title("Close Price Visualization")
plt.plot(df.Close)

df

"""# Plotting moving averages of 100 day

---


"""

ma100 = df.Close.rolling(100).mean()
ma100

plt.figure(figsize = (12,6))
plt.plot(df.Close)
plt.plot(ma100, 'r')
plt.title('Graph Of Moving Averages Of 100 Days')

"""# Defining 200 days moving averages and plotting comparision graph with 100 days moving averages

---


"""

ma200 = df.Close.rolling(200).mean()
ma200

plt.figure(figsize = (12,6))
plt.plot(df.Close)
plt.plot(ma100, 'r')
plt.plot(ma200, 'g')
plt.title('Comparision Of 100 Days And 200 Days Moving Averages')

df.shape

"""# Spliting the dataset into training (70%) and testing (30%) set"""

# Splitting data into training and testing

train = pd.DataFrame(data[0:int(len(data)*0.70)])
test = pd.DataFrame(data[int(len(data)*0.70): int(len(data))])

print(train.shape)
print(test.shape)

train.head()

test.head()

"""# Using MinMax scaler for normalization of the dataset

---


"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))

train_close = train.iloc[:, 4:5].values
test_close = test.iloc[:, 4:5].values

data_training_array = scaler.fit_transform(train_close)
data_training_array

x_train = []
y_train = []

for i in range(100, data_training_array.shape[0]):
    x_train.append(data_training_array[i-100: i])
    y_train.append(data_training_array[i, 0])

x_train, y_train = np.array(x_train), np.array(y_train)

x_train.shape

"""# ML Model (LSTM)

---


"""

from tensorflow.keras.layers import Dense, Dropout, LSTM
from tensorflow.keras.models import Sequential

model = Sequential()
model.add(LSTM(units = 50, activation = 'relu', return_sequences=True
              ,input_shape = (x_train.shape[1], 1)))
model.add(Dropout(0.2))


model.add(LSTM(units = 60, activation = 'relu', return_sequences=True))
model.add(Dropout(0.3))


model.add(LSTM(units = 80, activation = 'relu', return_sequences=True))
model.add(Dropout(0.4))


model.add(LSTM(units = 120, activation = 'relu'))
model.add(Dropout(0.5))

model.add(Dense(units = 1))

model.summary()

"""# Training the model

---


"""

model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MAE'])
# Assuming x_test and y_test will be defined in later cells
# For now, fitting the model without validation data
model.fit(x_train, y_train, epochs = 50) # Remove validation_data

model.save('keras_model.h5')

test_close.shape
test_close

past_100_days = pd.DataFrame(train_close[-100:])

test_df = pd.DataFrame(test_close)

"""**Defining the final dataset for testing by including last 100 coloums of the training dataset to get the prediction from the 1st column of the testing dataset.**

---

"""

final_df = pd.concat([past_100_days, test_df], ignore_index=True)

final_df.head()

input_data = scaler.fit_transform(final_df)
input_data

input_data.shape

"""# Testing the model

---


"""

x_test = []
y_test = []
for i in range(100, input_data.shape[0]):
   x_test.append(input_data[i-100: i])
   y_test.append(input_data[i, 0])

x_test, y_test = np.array(x_test), np.array(y_test)
print(x_test.shape)
print(y_test.shape)

x_test = []
y_test = []
for i in range(100, input_data.shape[0]):
   x_test.append(input_data[i-100: i])
   y_test.append(input_data[i, 0])

x_test, y_test = np.array(x_test), np.array(y_test)

# Compile the model
model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MAE'])
x_test = []
y_test = []
for i in range(100, input_data.shape[0]):
   x_test.append(input_data[i-100: i])
   y_test.append(input_data[i, 0])

x_test, y_test = np.array(x_test), np.array(y_test)

# Compile the model
model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MAE'])

# Train the model
model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 50)

"""# Making prediction and plotting the graph of predicted vs actual values

---


"""

# Making predictions

y_pred = model.predict(x_test)

y_pred.shape

y_test

y_pred

scaler.scale_

scale_factor = 1/0.00985902
y_pred = y_pred * scale_factor
y_test = y_test * scale_factor

plt.figure(figsize = (12,6))
plt.plot(y_test, 'b', label = "Original Price")
plt.plot(y_pred, 'r', label = "Predicted Price")
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

"""# Model evaluation"""

from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_test, y_pred)
print("Mean absolute error on test set: ", mae)